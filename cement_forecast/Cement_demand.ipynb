{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c9759f-cd5b-4531-886e-4bf64d6ea013",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# 1. Connect to your SQLite database\n",
    "# Replace \"your_database.db\" with your actual .db file path\n",
    "db_path = \"MIG_Cement_Records.db\"\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# 2. Write your SQL query\n",
    "query = \"SELECT * FROM sqlite_master;\"\n",
    "\n",
    "# 3. Fetch into a DataFrame\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# 4. Display the data\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0319d38a-4186-4d2e-9401-363afc714fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for table in [\"Sites\", \"CementTypes\", \"Operations\"]:\n",
    "#     query = f\"PRAGMA table_info({table});\"\n",
    "#     print(f\"\\nColumns in {table}:\")\n",
    "#     print(pd.read_sql_query(query, conn))\n",
    "\n",
    "for table in [\"Sites\", \"CementTypes\", \"Operations\"]:\n",
    "    print(f\"\\nPreview of {table}:\")\n",
    "    print(pd.read_sql_query(f\"SELECT * FROM {table} LIMIT 5;\", conn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17650707-8a7d-4717-9036-49a59b61527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    o.date,\n",
    "    o.site_id,\n",
    "    s.region,\n",
    "    s.behavior,\n",
    "    o.cement_type,\n",
    "    o.planned_pour_tonnes,\n",
    "    o.consumed_tonnes,\n",
    "    o.opening_inventory_tonnes,\n",
    "    o.deliveries_tonnes,\n",
    "    o.closing_inventory_tonnes,\n",
    "    o.rain_mm,\n",
    "    o.avg_temp_c,\n",
    "    o.silo_capacity\n",
    "FROM Operations o\n",
    "JOIN Sites s ON o.site_id = s.site_id\n",
    "JOIN CementTypes c ON o.cement_type = c.cement_type;\n",
    "\"\"\"\n",
    "\n",
    "df_joined = pd.read_sql_query(query, conn)\n",
    "print(df_joined)  # Should now show (32880, 11) if that’s the actual data\n",
    "# conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b197a40-d03b-4682-abe5-e8263b974d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to CSV\n",
    "df_joined.to_csv(\"cement_records_joined.csv\", index=False)\n",
    "\n",
    "print(\"Data saved to cement_records_joined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8d6d71-1c3a-4caf-9d6e-e833777016f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cement_records_joined.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1a93e5-542a-432f-959f-e341a1d45b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68974b6a-8de9-4bc5-b787-12f86cb807f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc1da1c-d7c2-4af5-b89e-06d4778a28bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"shape:\",df.shape)\n",
    "display(df.columns.tolist())\n",
    "display(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefe41a3-d899-4aa9-8a28-9570f469a71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_col = df.select_dtypes(include=[\"int64\",'float64']).columns\n",
    "numerical_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dab657-6b78-428a-aeba-fd68795d75fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[numerical_col] < 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be6e1df-a70d-4817-a83a-57ee4038acfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['inventory_check'] = (\n",
    "    df['opening_inventory_tonnes'] + df['deliveries_tonnes'] -df['consumed_tonnes']).round(2) == df['closing_inventory_tonnes'].round(2)\n",
    "\n",
    "df['inventory_check'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312b3565-6514-4b92-aef0-c181d28232ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"stock_out\"] = df[\"planned_pour_tonnes\"] >(df['closing_inventory_tonnes'] + df['deliveries_tonnes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0dec93-7726-484d-b1f2-72b10b4b76d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['over_capacity'] = df['closing_inventory_tonnes'] > df['silo_capacity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cf08b1-49fd-4acd-9828-63980367d482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['idle'] = ((df['planned_pour_tonnes'] == 0 & df['deliveries_tonnes'] == 0))\n",
    "\n",
    "df['idle'] = (df['planned_pour_tonnes'] == 0) & (df['deliveries_tonnes'] == 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470b4b55-eabf-47e5-a58d-77c8352c910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['waste_risk'] = (df['closing_inventory_tonnes'] > 0.85 * df['silo_capacity']) & (df['planned_pour_tonnes'] < 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c398386-c773-4f2e-bc30-d9cac32cbc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pour_disrupted'] = (df['planned_pour_tonnes'] > 0) & (df['consumed_tonnes'] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0eb1db-d4a0-4915-beba-ae54a0e78669",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpi_summary = df.groupby('site_id').agg(\n",
    "    total_days =(\"date\",'count'),\n",
    "    total_consumed_tonnes =('consumed_tonnes','sum'),\n",
    "    avg_daily_consumed = ('consumed_tonnes','mean'),\n",
    "    stockout_pct = ('stock_out',lambda x : round(x.mean()*100,2)),\n",
    "    overcapacity = ('over_capacity',lambda x : round(x.mean()*100,2)),\n",
    "    idle_pct = ('idle',lambda x : round(x.mean()*100,2)),\n",
    "    waste_risk_pct = ('waste_risk',lambda x : round(x.mean()*100,2)),\n",
    "    pour_disrupted_pct = ('pour_disrupted',lambda x : round(x.mean()*100,2)),\n",
    "    silo_capacity = ('silo_capacity','first'),\n",
    "    region = ('region','first')\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "\n",
    "kpi_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04c7c53-7ca5-4d04-ab95-9d80bcc078ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 Sites by Average Daily Consumption\n",
    "\n",
    "top5_consumption = kpi_summary.sort_values(\n",
    "    by=\"avg_daily_consumed\", ascending=False\n",
    ").head(5)\n",
    "\n",
    "print(\"Top 5 Sites by Avg Daily Consumption:\")\n",
    "print(top5_consumption[[\"site_id\", \"avg_daily_consumed\", \"region\"]])\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "top5_consumption = kpi_summary.nlargest(5, \"avg_daily_consumed\")\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.bar(top5_consumption[\"site_id\"], top5_consumption[\"avg_daily_consumed\"], color=\"skyblue\")\n",
    "plt.title(\"Top 5 Sites by Avg Daily Consumption\")\n",
    "plt.xlabel(\"Site ID\")\n",
    "plt.ylabel(\"Avg Daily Consumption (tonnes)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7944691-c462-42ab-985b-ad30bb85191f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Worst 5 Sites by Stockout %\n",
    "\n",
    "worst5_stockout = kpi_summary.sort_values(\n",
    "    by=\"stockout_pct\", ascending=False\n",
    ").head(5)\n",
    "\n",
    "print(\"Worst 5 Sites by Stockout %:\")\n",
    "print(worst5_stockout[[\"site_id\", \"stockout_pct\", \"region\"]])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf7e53b-a78c-4259-a779-62d1ad7aedcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sites with Highest Pour Disruption\n",
    "\n",
    "top5_total1 = kpi_summary.nlargest(5, \"total_consumed_tonnes\")\n",
    "print(\"Top 5 Sites by Total Consumption:\")\n",
    "print(top5_total1[[\"site_id\", \"total_consumed_tonnes\", \"region\"]])\n",
    "\n",
    "\n",
    "top5_total = kpi_summary.nlargest(15, \"total_consumed_tonnes\")\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.bar(top5_total1[\"site_id\"], top5_total1[\"total_consumed_tonnes\"], color=\"green\")\n",
    "plt.title(\"Top 5 Sites by Highest pour Distrption\")\n",
    "plt.xlabel(\"Site ID\")\n",
    "plt.ylabel(\"Total Consumed (tonnes)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e51810f-0fd2-46f5-99a8-9dc96754eff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top_site =kpi_summary.sort_values('total_consumed_tonnes', ascending = False).head(20)\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.subplot(2,3,2)\n",
    "plt.bar(top_site['site_id'],top_site['total_consumed_tonnes'])\n",
    "plt.title =(\"Top 20 sited by total cement consumption\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(15000, top_site['total_consumed_tonnes'].max() *1.2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d957746f-9043-4fb8-a198-f819f19d592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  seaborn as sns\n",
    "\n",
    "risk_site =kpi_summary.sort_values('stockout_pct', ascending = False).head(10)\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.subplot(2,3,2)\n",
    "sns.barplot(x ='site_id',y='stockout_pct',data = risk_site)\n",
    "plt.title =(\"Top 10 sited by stockout Risk %\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(30,70)\n",
    "# plt.ylim(15000, top_site['total_consumed_tonnes'].max() *1.2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66aa6a18-fddf-4e37-bda3-23a52d334c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "overcapacity_site =kpi_summary.sort_values('overcapacity', ascending = False).head(10)\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.subplot(2,3,2)\n",
    "sns.barplot(x ='site_id',y='overcapacity',data = overcapacity_site)\n",
    "plt.title =(\"Top 10 sited by overcapacity_pct %\")\n",
    "plt.xticks(rotation=45)\n",
    "# plt.ylim(10,60)\n",
    "# plt.ylim(15000, top_site['total_consumed_tonnes'].max() *1.2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c167bdfe-99f7-4b49-be69-12365a2e1fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "idle_site =kpi_summary.sort_values('idle_pct', ascending = False).head(10)\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.subplot(2,3,2)\n",
    "sns.barplot(x ='site_id',y='idle_pct',data = idle_site)\n",
    "plt.title =(\"Top 10 sited by IDLE\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca293972-f91d-4166-a051-eb46e4227694",
   "metadata": {},
   "outputs": [],
   "source": [
    "waste_site =kpi_summary.sort_values('waste_risk_pct', ascending = False).head(10)\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.subplot(2,3,2)\n",
    "sns.barplot(x ='site_id',y='waste_risk_pct',data = waste_site)\n",
    "plt.title=(\"Top 10 sited by Waste Risk %\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdaedb0-808a-400f-a90a-ddeb8b1a0471",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['utilization+pct'] = df['closing_inventory_tonnes'] / df['silo_capacity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2cb2a5-a0a5-40f5-b2f6-1c0cdffcba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "utilization_summary = df.groupby('site_id')['utilization+pct'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3474a359-e942-42d0-a159-da86f268c37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "utilization_summary.plot(kind = 'bar' , title='average silo utilization by site',figsize=(15,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6463b927-0202-477d-9606-d9135ef2a77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "# Create subplot slot (2 rows, 3 columns, position 2)\n",
    "ax = plt.subplot(2,3,2)\n",
    "\n",
    "# Plot on that axis\n",
    "utilization_summary.plot(\n",
    "    kind=\"bar\",\n",
    "    x=\"site_id\",\n",
    "    y=\"avg_silo_utilization\",   # change to your column\n",
    "    title=\"Average Silo Utilization by Site\",\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80195e97-8343-4c07-93bb-18fe36e01397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select top 10 sites for each KPI\n",
    "top10_consumed = kpi_summary.nlargest(10, \"total_consumed_tonnes\")\n",
    "top10_avg = kpi_summary.nlargest(10, \"avg_daily_consumed\")\n",
    "top10_stockout = kpi_summary.nlargest(10, \"stockout_pct\")\n",
    "top10_overcap = kpi_summary.nlargest(10, \"overcapacity\")\n",
    "top10_idle = kpi_summary.nlargest(10, \"idle_pct\")\n",
    "top10_waste = kpi_summary.nlargest(10, \"waste_risk_pct\")\n",
    "\n",
    "# Create dashboard grid (2 rows x 3 cols)\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# --- Plot 1: Total Consumption ---\n",
    "axes[0,0].bar(top10_consumed[\"site_id\"], top10_consumed[\"total_consumed_tonnes\"], color=\"green\")\n",
    "axes[0,0].set_title(\"Top 10 Sites by Total Consumption\")\n",
    "axes[0,0].set_xlabel(\"Site ID\")\n",
    "axes[0,0].set_ylabel(\"Tonnes\")\n",
    "axes[0,0].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "# --- Plot 2: Avg Daily Consumption ---\n",
    "axes[0,1].bar(top10_avg[\"site_id\"], top10_avg[\"avg_daily_consumed\"], color=\"skyblue\")\n",
    "axes[0,1].set_title(\"Top 10 Sites by Avg Daily Consumption\")\n",
    "axes[0,1].set_xlabel(\"Site ID\")\n",
    "axes[0,1].set_ylabel(\"Tonnes\")\n",
    "axes[0,1].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "# --- Plot 3: Stockout % ---\n",
    "axes[0,2].bar(top10_stockout[\"site_id\"], top10_stockout[\"stockout_pct\"], color=\"salmon\")\n",
    "axes[0,2].set_title(\"Top 10 Sites by Stockout %\")\n",
    "axes[0,2].set_xlabel(\"Site ID\")\n",
    "axes[0,2].set_ylabel(\"%\")\n",
    "axes[0,2].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "# --- Plot 4: Overcapacity % ---\n",
    "axes[1,0].bar(top10_overcap[\"site_id\"], top10_overcap[\"overcapacity\"], color=\"orange\")\n",
    "axes[1,0].set_title(\"Top 10 Sites by Overcapacity %\")\n",
    "axes[1,0].set_xlabel(\"Site ID\")\n",
    "axes[1,0].set_ylabel(\"%\")\n",
    "axes[1,0].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "# --- Plot 5: Idle % ---\n",
    "axes[1,1].bar(top10_idle[\"site_id\"], top10_idle[\"idle_pct\"], color=\"purple\")\n",
    "axes[1,1].set_title(\"Top 10 Sites by Idle %\")\n",
    "axes[1,1].set_xlabel(\"Site ID\")\n",
    "axes[1,1].set_ylabel(\"%\")\n",
    "axes[1,1].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "# --- Plot 6: Waste Risk % ---\n",
    "axes[1,2].bar(top10_waste[\"site_id\"], top10_waste[\"waste_risk_pct\"], color=\"red\")\n",
    "axes[1,2].set_title(\"Top 10 Sites by Waste Risk %\")\n",
    "axes[1,2].set_xlabel(\"Site ID\")\n",
    "axes[1,2].set_ylabel(\"%\")\n",
    "axes[1,2].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669b2a00-b0da-41ae-b28c-7ae0ff6cdf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_kpi = df.groupby('behavior').agg(\n",
    "    avg_stockout=('stock_out', 'mean'),\n",
    "    avg_overcapacity=('over_capacity', 'mean'),\n",
    "    avg_waste_risk=('waste_risk', 'mean')\n",
    ")\n",
    "# behavior_kpi.plot(kind='bar',figsize(15,6),title='kpi Comparison by site behavious')\n",
    "\n",
    "behavior_kpi.plot(\n",
    "    kind='bar',\n",
    "    figsize=(15,6),\n",
    "    title='KPI Comparison by Site Behavior'\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel(\"Average Value\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc0e5a7-cec0-4723-9255-359d03c44ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kpi comparison by site Behavior\n",
    "#Comparison key performace indicator across different site Behavior to identify trends\n",
    "\n",
    "site_usage = df.groupby('site_id')['consumed_tonnes'].sum().sort_values(ascending=False)\n",
    "\n",
    "total_usage = site_usage.sum()\n",
    "top5=site_usage.head(5)\n",
    "top5_share = round(top5.sum() / total_usage * 100,2)\n",
    "\n",
    "display(top5)\n",
    "display(top5_share)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5624e70c-bc9b-4bf8-ab72-f5e1542f6b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by site and take mean of selected columns\n",
    "site_usage = df.groupby('site_id')[['closing_inventory_tonnes', 'planned_pour_tonnes']].mean()\n",
    "\n",
    "# Sort by closing inventory (you can also sort by 'stockout_pct' if you prefer)\n",
    "site_usage = site_usage.sort_values('closing_inventory_tonnes', ascending=False)\n",
    "\n",
    "# Total usage for closing inventory\n",
    "total_usage = site_usage['closing_inventory_tonnes'].sum()\n",
    "\n",
    "# Top 5 sites\n",
    "top5 = site_usage.head(10)\n",
    "\n",
    "# Percentage share of top 5 sites\n",
    "top5_share = round(top5['closing_inventory_tonnes'].sum() / total_usage * 100, 2)\n",
    "\n",
    "display(top5)\n",
    "display(top5_share)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34372a7-0be8-4922-8ed7-1539705cc446",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cement Type Demand share\n",
    "#Understanding which cement types most consumed to optimize inventory chain.\n",
    "cement_demand =df.groupby('cement_type')[\"consumed_tonnes\"].sum().sort_values()\n",
    "cement_demand.plot(kind='pie',autopct='%1.1f%%',figsize=(6,6),title='Cement Type Demand Share')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9531bc44-ca09-4408-9152-8fd89a488440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monthly Cement Demand Seasionality\n",
    "#Identifying seasonal treds in cement comparison to better plan logistic abd inventory.\n",
    "df[\"month\"] = df['date'].dt.to_period(\"M\")\n",
    "monthly_demand = df.groupby('month')['consumed_tonnes'].sum()\n",
    "monthly_demand.plot(figsize=(12,5),title='Monthly cemnet Demand Seasonality')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af78034-0f69-4853-9491-bd9bde53c6bf",
   "metadata": {},
   "source": [
    "MODELIMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dc49cb-eac7-4d33-8686-3bb1a7e363ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361e44b2-c7e3-43af-9d45-054c548fc740",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_id = 'SITE_001'\n",
    "site_df = df[df['site_id'] == site_id].copy()\n",
    "site_df.set_index('date',inplace=True)\n",
    "site_df = site_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2c924f-251e-42d7-b19a-f10a93ffc83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(site_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0e8df6-b549-4b14-b783-90dc57b6f3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = site_df['consumed_tonnes']\n",
    "\n",
    "# X= site_df[['planned_pour_tonnes', 'rain_mm', 'avg_temp_c']]\n",
    "\n",
    "# # Train-test split first\n",
    "# # split_index = int(len(site_df) * 0.8)\n",
    "# # y_train, y_test = X.iloc[:split_index], X.iloc[split_index:]\n",
    "# # y_train, y_test = y.iloc[:split_index], y.iloc[split_index:]\n",
    "# X_test,y_test,X_train,y_train(X,y,test_size = 0.2, random_state =42)\n",
    "# print(X_train.shape, y_train.shape)\n",
    "# print(X_test.shape, y_test.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = site_df[['planned_pour_tonnes', 'rain_mm', 'avg_temp_c']]\n",
    "y = site_df['consumed_tonnes']  # or your target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5512e9af-a334-4e78-879b-d31ecc8e4a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "\n",
    "# Train-test split first\n",
    "split_index = int(len(site_df) * 0.8)\n",
    "y_train, y_test = y.iloc[:split_index], y.iloc[split_index:]\n",
    "\n",
    "# Fit AutoReg (only y, no exog allowed here)\n",
    "model = AutoReg(y_train, lags=12)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())\n",
    "\n",
    "# Forecast same length as y_test\n",
    "# ar_forecast = results.predict(\n",
    "#     start=y_test.index[0], \n",
    "#     end=y_test.index[-1]\n",
    "# )\n",
    "\n",
    "ar_forecast = results.predict(\n",
    "    start=y_test.index[0], \n",
    "    end=y_test.index[-1]\n",
    ")\n",
    "\n",
    "# Align forecast index with y_test\n",
    "ar_forecast = pd.Series(ar_forecast, index=y_test.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a8e763-6a72-400d-993f-127c5fb7ec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e1771a-2a37-4028-85a5-606c963573f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Actual values\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=y_test.index,\n",
    "    y=y_test,\n",
    "    mode='lines',\n",
    "    name=\"Actual\",\n",
    "    line=dict(color='black')\n",
    "))\n",
    "\n",
    "# Forecasted values\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=y_test.index,\n",
    "    y=ar_forecast,\n",
    "    mode='lines',\n",
    "    name=\"Forecast\",\n",
    "    line=dict(color='red', dash='dash')\n",
    "))\n",
    "\n",
    "# Layout customization\n",
    "fig.update_layout(\n",
    "    title=f'AUTOREG FORECAST VS ACTUAL - {site_id}',\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Cement Consumed (Tonnes)\",\n",
    "    legend=dict(x=0, y=1),\n",
    "    template='plotly_white',\n",
    "    width=1000,\n",
    "    height=450\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8b410e-1a38-4923-a607-28ec119f449c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "split_index = int(len(site_df) * 0.8)\n",
    "X_train, X_test = X.iloc[:split_index], X.iloc[split_index:]\n",
    "y_train, y_test = y.iloc[:split_index], y.iloc[split_index:]\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2ade6c-0498-4187-9fad-6a520d3fd1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "model = LGBMRegressor(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf61391-86ea-4c6d-8d17-e8fac883295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualisation SARIMAX Forecast Vs actual\n",
    "fig = go.Figure()\n",
    "\n",
    "# Actual Values\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=y_test.index,\n",
    "    y=y_test,\n",
    "    mode='lines',\n",
    "    name=\"Actual\",\n",
    "    line=dict(color='black')\n",
    "))\n",
    "\n",
    "# Forecast Values\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=y_test.index,\n",
    "    y=ar_forecast,\n",
    "    mode='lines',\n",
    "    name='Forecast',\n",
    "    line=dict(color='green', dash='dash')\n",
    "))\n",
    "\n",
    "# Layout\n",
    "fig.update_layout(\n",
    "    title=f'LIGHTGB FORECAST VS ACTUAL - {site_id}',\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Cement Consumed (Tonnes)\",\n",
    "    legend=dict(x=0, y=1),\n",
    "    template='plotly_white',\n",
    "    width=1000,\n",
    "    height=450\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ea1c0a-bf12-4034-8aaf-67abd96d8d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Metrics\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def print_metrics(y_true, y_pred, label):\n",
    "    mask = y_true != 0\n",
    "    mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    print(f\"{label} - MAPE: {mape:.2f}%, RMSE: {rmse:.2f} tonnes\")\n",
    "\n",
    "\n",
    "# Comparing SARIMAX and Random Forest\n",
    "print_metrics(y_test,ar_forecast, \"AUTOREG\")\n",
    "print_metrics(y_test, y_pred, \"LIGHTGB Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0977213-8d1f-4540-8e0a-4dda91543161",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Feature Engineering ---\n",
    "\n",
    "# Filter for one site\n",
    "site_df = df[df['site_id'] == 'SITE_001'].copy().sort_values('date')\n",
    "site_df.set_index('date', inplace=True)\n",
    "\n",
    "# Lag features\n",
    "site_df[\"lag_1\"] = site_df['consumed_tonnes'].shift(1)\n",
    "site_df[\"lag_3\"] = site_df['consumed_tonnes'].shift(3)\n",
    "site_df[\"lag_7\"] = site_df['consumed_tonnes'].shift(7)\n",
    "\n",
    "# Rolling statistics\n",
    "site_df['rolling_mean_3'] = site_df['consumed_tonnes'].rolling(3).mean()\n",
    "site_df['rolling_std_7'] = site_df['consumed_tonnes'].rolling(7).std()\n",
    "\n",
    "# Date-based features\n",
    "site_df['day_of_week'] = site_df.index.dayofweek\n",
    "site_df['week_of_year'] = site_df.index.isocalendar().week.astype(int)\n",
    "\n",
    "# Interaction features\n",
    "site_df['rain_x_pour'] = site_df['rain_mm'] * site_df['planned_pour_tonnes']\n",
    "site_df['temp_x_pour'] = site_df['avg_temp_c'] * site_df['planned_pour_tonnes']\n",
    "\n",
    "# Inventory features\n",
    "site_df['inventory_gap'] = (\n",
    "    site_df['opening_inventory_tonnes'] + site_df['deliveries_tonnes'] - site_df['planned_pour_tonnes']\n",
    ")\n",
    "site_df['inventory_ratio'] = site_df['closing_inventory_tonnes'] / site_df['silo_capacity']\n",
    "\n",
    "# Encoding categorical variables\n",
    "site_df['behavior_encoded'] = site_df['behavior'].astype('category').cat.codes\n",
    "site_df['cement_type_encoded'] = site_df['cement_type'].astype('category').cat.codes\n",
    "\n",
    "# Drop NaNs from lag/rolling features\n",
    "site_df.dropna(inplace=True)\n",
    "\n",
    "# --- Define features and target ---\n",
    "features = [\n",
    "    \"planned_pour_tonnes\", \"rain_mm\", \"avg_temp_c\",\n",
    "    \"lag_1\", \"lag_3\", \"lag_7\",\n",
    "    \"rolling_mean_3\", \"rolling_std_7\",\n",
    "    \"rain_x_pour\", \"temp_x_pour\",\n",
    "    \"inventory_gap\", \"inventory_ratio\",\n",
    "    \"behavior_encoded\", \"cement_type_encoded\",  # fixed duplicate\n",
    "    \"day_of_week\", \"week_of_year\"\n",
    "]\n",
    "\n",
    "X = site_df[features]\n",
    "y = site_df[\"consumed_tonnes\"]\n",
    "\n",
    "# --- Train-test split (time series) ---\n",
    "split_index = int(len(site_df) * 0.8)\n",
    "X_train, X_test = X.iloc[:split_index], X.iloc[split_index:]\n",
    "y_train, y_test = y.iloc[:split_index], y.iloc[split_index:]\n",
    "\n",
    "# --- Train model ---\n",
    "model = LGBMRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "lgb =model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = lgb.predict(X_test)\n",
    "\n",
    "# --- Evaluate ---\n",
    "def print_metrics(y_true, y_pred, label):\n",
    "    mask = y_true != 0\n",
    "    mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    print(f\"{label} - MAPE: {mape:.2f}%, RMSE: {rmse:.2f} tonnes\")\n",
    "\n",
    "print_metrics(y_test, y_pred, \"LightGBM (Enhanced Features)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8ca1a4-18b9-4930-bcb8-d04b519095bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualisation Random Forest Forecast Vs actual\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Actual Values\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=y_test.index,\n",
    "    y=y_test,\n",
    "    mode='lines',\n",
    "    name=\"Actual\",\n",
    "    line=dict(color='black')\n",
    "))\n",
    "\n",
    "# Forecast Values\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=y_test.index,\n",
    "    y=y_pred,\n",
    "    mode='lines',\n",
    "    name='Forecast',\n",
    "    line=dict(color='yellow',dash='dash')\n",
    "))\n",
    "\n",
    "# Layout\n",
    "fig.update_layout(\n",
    "    title=f'LIGHTGB FORECAST VS ACTUAL - {site_id}',\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Cement Consumed (Tonnes)\",\n",
    "    legend=dict(x=0, y=1),\n",
    "    template='plotly_white',\n",
    "    width=1000,\n",
    "    height=450\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3453a73f-3f38-45e2-b0db-ddd4e584f5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import feature in the dataset\n",
    "\n",
    "# feat_important = pd.Series(rf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "# print(feat_important.head(10))\n",
    "\n",
    "# For LightGBM\n",
    "feat_important = pd.Series(\n",
    "    model.feature_importances_, \n",
    "    index=model.feature_name_\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "print(feat_important.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203c7b58-fd17-4881-a992-8741dbe4b9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get feature importances\n",
    "feat_important = pd.Series(\n",
    "    model.feature_importances_,\n",
    "    index=model.feature_name_\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "# Print top features\n",
    "print(\"Top 10 features:\\n\", feat_important.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210a4df2-5cc3-44de-b7fd-6441963655d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "feat_important.head(10).plot(\n",
    "    kind='bar', color='skyblue', edgecolor='black', ax=ax\n",
    ")\n",
    "ax.set_title(\"Top 10 Feature Importances - LightGBM\")\n",
    "ax.set_ylabel(\"Importance Score\")\n",
    "ax.set_xlabel(\"Features\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885fa8c6-0aa8-41c6-868e-1af44b77f370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature important visualisation\n",
    "\n",
    "# Feature importance\n",
    "importance = pd.Series(lgb.feature_importances_, index=features).sort_values()\n",
    "\n",
    "# Plot\n",
    "importance.plot(kind='barh', figsize=(12,5), title='Feature Importance - Random Forest')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1650019-d7a3-4548-950d-3dc3af82614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764e9db0-5821-4919-9cd2-26bec3a77aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parameters\n",
    "silo_capacity = 1000\n",
    "initial_inventory = 600\n",
    "lead_time_days = 3\n",
    "reorder_threshold = 0.2 * silo_capacity\n",
    "target_inventory = 0.8 * silo_capacity\n",
    "buffer_rain_threshold = 10   # mm rainfall threshold\n",
    "buffer_increase = 0.1\n",
    "\n",
    "# DataFrame to store result\n",
    "df_sim = pd.DataFrame({\n",
    "    \"date\": X_test.index,\n",
    "    \"forecasted_consumption\": y_pred,\n",
    "    \"rain_forecast_mm\": X_test[\"rain_mm\"].values\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e225ecb-bc57-4ff0-8268-c0a18bbd9fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d086552-67cf-4813-91fd-f673462533eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sim[\"sim_inventory\"] = np.nan\n",
    "# df_sim['reoder_flag'] = False\n",
    "# df_sim['recommended_delivery_quantity'] = 0.0\n",
    "# df_sim['buffer_applied'] = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize columns\n",
    "df_sim[\"sim_inventory\"] = 0.0\n",
    "df_sim[\"reorder_flag\"] = False\n",
    "df_sim[\"buffer_applied\"] = False\n",
    "df_sim[\"recommended_delivery_date\"] = pd.NaT\n",
    "df_sim[\"recommended_delivery_quantity\"] = 0.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c9435b-249c-499d-b0dc-55e2c041184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize inventory\n",
    "inventory = initial_inventory\n",
    "delivery_queue = {}\n",
    "\n",
    "# Simulation loop\n",
    "for i, row in df_sim.iterrows():\n",
    "    today = row[\"date\"]\n",
    "\n",
    "    # If a delivery is due, add it to inventory\n",
    "    if today in delivery_queue:\n",
    "        inventory += delivery_queue[today]\n",
    "        inventory = min(inventory, silo_capacity)\n",
    "        del delivery_queue[today]\n",
    "\n",
    "    # Subtract today's consumption\n",
    "    consumption = row[\"forecasted_consumption\"]\n",
    "    inventory -= consumption\n",
    "\n",
    "    # Record today's inventory\n",
    "    df_sim.loc[i, \"sim_inventory\"] = inventory\n",
    "\n",
    "    # Check reorder condition\n",
    "    if inventory < reorder_threshold:\n",
    "        df_sim.loc[i, \"reorder_flag\"] = True\n",
    "        delivery_date = today + pd.Timedelta(days=lead_time_days)\n",
    "\n",
    "        # Calculate delivery qty\n",
    "        delivery_qty = target_inventory - inventory\n",
    "        if row[\"rain_forecast_mm\"] > buffer_rain_threshold:\n",
    "            delivery_qty *= (1 + buffer_increase)\n",
    "            df_sim.loc[i, \"buffer_applied\"] = True\n",
    "\n",
    "        # Cap by silo capacity\n",
    "        delivery_qty = min(delivery_qty, silo_capacity - inventory)\n",
    "        delivery_queue[delivery_date] = delivery_qty\n",
    "\n",
    "        # Save delivery details\n",
    "        df_sim.loc[i, \"recommended_delivery_date\"] = delivery_date.strftime(\"%Y-%m-%d\")\n",
    "        df_sim.loc[i, \"recommended_delivery_quantity\"] = round(delivery_qty, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa79a39-6f87-4556-abf2-2de132bf18bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KPIs\n",
    "stockouts = (df_sim[\"sim_inventory\"] < 0).sum()\n",
    "service_level = 100 * (1 - stockouts / len(df_sim))\n",
    "avg_inventory = df_sim[\"sim_inventory\"].mean()\n",
    "num_deliveries = df_sim[\"reorder_flag\"].sum()\n",
    "\n",
    "print(f\"Service level: {service_level:.2f}%\")\n",
    "print(f\"Stockouts: {stockouts}\")\n",
    "print(f\"Average inventory: {avg_inventory:.2f} tonnes\")\n",
    "print(f\"Number of deliveries: {num_deliveries}\")\n",
    "\n",
    "# Output\n",
    "output_df = df_sim[\n",
    "    [\"date\", \"forecasted_consumption\", \"sim_inventory\", \"reorder_flag\",\n",
    "     \"recommended_delivery_date\", \"recommended_delivery_quantity\", \"buffer_applied\"]\n",
    "]\n",
    "\n",
    "output_df.head(50)\n",
    "\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49307043-ae4e-45e8-b9a3-93b95bf0fd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from lightgbm import LGBMRegressor\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# ---------------- Feature Engineering ----------------\n",
    "def engineer_features(df, site_id):\n",
    "    # Ensure datetime\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    # Filter by site\n",
    "    site_df = df[df['site_id'] == site_id].copy().sort_values('date')\n",
    "    site_df.set_index('date', inplace=True)\n",
    "\n",
    "    # Lag features\n",
    "    site_df[\"lag_1\"] = site_df['consumed_tonnes'].shift(1)\n",
    "    site_df[\"lag_3\"] = site_df['consumed_tonnes'].shift(3)\n",
    "    site_df[\"lag_7\"] = site_df['consumed_tonnes'].shift(7)\n",
    "    \n",
    "    # Rolling statistics\n",
    "    site_df['rolling_mean_3'] = site_df['consumed_tonnes'].rolling(3).mean()\n",
    "    site_df['rolling_std_7'] = site_df['consumed_tonnes'].rolling(7).std()\n",
    "\n",
    "    # Date-based features\n",
    "    site_df['day_of_week'] = site_df.index.dayofweek\n",
    "    site_df['week_of_year'] = site_df.index.isocalendar().week.astype(int)\n",
    "\n",
    "    # Interaction features\n",
    "    site_df['rain_x_pour'] = site_df['rain_mm'] * site_df['planned_pour_tonnes']\n",
    "    site_df['temp_x_pour'] = site_df['avg_temp_c'] * site_df['planned_pour_tonnes']\n",
    "\n",
    "    # Inventory features\n",
    "    site_df['inventory_gap'] = (\n",
    "        site_df['opening_inventory_tonnes'] + site_df['deliveries_tonnes'] - site_df['planned_pour_tonnes']\n",
    "    )\n",
    "    site_df['inventory_ratio'] = site_df['closing_inventory_tonnes'] / site_df['silo_capacity']\n",
    "\n",
    "    # Encoding categorical variables\n",
    "    site_df['behavior_encoded'] = site_df['behavior'].astype('category').cat.codes\n",
    "    site_df['cement_type_encoded'] = site_df['cement_type'].astype('category').cat.codes\n",
    "\n",
    "    # Drop NaNs from lag/rolling features\n",
    "    site_df.dropna(inplace=True)\n",
    "\n",
    "    return site_df\n",
    "\n",
    "\n",
    "# ---------------- Model Training ----------------\n",
    "def train_rf_forecast(site_df):\n",
    "    # Features\n",
    "    features = [\n",
    "        \"planned_pour_tonnes\", \"rain_mm\", \"avg_temp_c\",\n",
    "        \"lag_1\", \"lag_3\", \"lag_7\",\n",
    "        \"rolling_mean_3\", \"rolling_std_7\",\n",
    "        \"rain_x_pour\", \"temp_x_pour\",\n",
    "        \"inventory_gap\", \"inventory_ratio\",\n",
    "        \"behavior_encoded\", \"cement_type_encoded\",\n",
    "        \"day_of_week\", \"week_of_year\"\n",
    "    ]\n",
    "\n",
    "    X = site_df[features]\n",
    "    y = site_df[\"consumed_tonnes\"]\n",
    "\n",
    "    # Train-test split (time series)\n",
    "    # split_index = int(len(X) * 0.8)\n",
    "    # X_train, X_test = X.iloc[:split_index], X.iloc[split_index:]\n",
    "    # y_train, y_test = y.iloc[:split_index], y.iloc[split_index:]\n",
    "    X_train, X_test,y_train, y_test=train_test_split(X,y, test_size =0.2,random_state = 42)\n",
    "\n",
    "    # Train model\n",
    "    model = LGBMRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    return model, X_test, y_test, y_pred\n",
    "\n",
    "\n",
    "model, X_test, y_test, y_pred = train_rf_forecast(site_df)\n",
    "print_metrics(y_test, y_pred, \"LightGBM (Enhanced Features)\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1091b85e-b301-4ee9-a09b-9168859d89ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_inventory(\n",
    "    df_sim,\n",
    "    initial_inventory,\n",
    "    silo_capacity,\n",
    "    reorder_threshold,\n",
    "    target_inventory,\n",
    "    lead_time_days=2,\n",
    "    buffer_rain_threshold=10,\n",
    "    buffer_increase=0.1\n",
    "):\n",
    "\n",
    "\n",
    "    # Add new columns\n",
    "    df_sim = df_sim.copy()\n",
    "    df_sim[\"sim_inventory\"] = np.nan\n",
    "    df_sim[\"reorder_flag\"] = False\n",
    "    df_sim[\"buffer_applied\"] = False\n",
    "    df_sim[\"recommended_delivery_date\"] = None\n",
    "    df_sim[\"recommended_delivery_quantity\"] = 0.0\n",
    "\n",
    "    # Simulation loop\n",
    "    for i, row in df_sim.iterrows():\n",
    "        today = row[\"date\"]\n",
    "\n",
    "        # If a delivery is due today, add it\n",
    "        if today in delivery_queue:\n",
    "            inventory += delivery_queue[today]\n",
    "            inventory = min(inventory, silo_capacity)  # cap\n",
    "            del delivery_queue[today]\n",
    "\n",
    "        # Subtract today's consumption\n",
    "        consumption = row[\"forecasted_consumption\"]\n",
    "        inventory -= consumption\n",
    "\n",
    "        # Record today's inventory\n",
    "        df_sim.at[i, \"sim_inventory\"] = inventory\n",
    "\n",
    "        # Check reorder condition\n",
    "        if inventory < reorder_threshold:\n",
    "            df_sim.at[i, \"reorder_flag\"] = True\n",
    "            delivery_date = today + pd.Timedelta(days=lead_time_days)\n",
    "\n",
    "            # Calculate delivery qty\n",
    "            delivery_qty = target_inventory - inventory\n",
    "            if row[\"rain_forecast_mm\"] > buffer_rain_threshold:\n",
    "                delivery_qty *= (1 + buffer_increase)\n",
    "                df_sim.at[i, \"buffer_applied\"] = True\n",
    "\n",
    "            # Cap delivery by silo capacity\n",
    "            delivery_qty = min(delivery_qty, silo_capacity - inventory)\n",
    "\n",
    "            # Schedule delivery\n",
    "            delivery_queue[delivery_date] = delivery_qty\n",
    "\n",
    "            # Save delivery details\n",
    "            df_sim.at[i, \"recommended_delivery_date\"] = delivery_date.strftime(\"%Y-%m-%d\")\n",
    "            df_sim.at[i, \"recommended_delivery_quantity\"] = round(delivery_qty, 2)\n",
    "\n",
    "    return df_sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188263f0-c3f2-470f-8553-1d222eee7b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def run_pipeline(df, site_metadata, lead_time_days=2, metadata_file=\"pipeline_metadata.json\"):\n",
    "    all_metadata = {}\n",
    "\n",
    "    for site_id, config in site_metadata.items():\n",
    "        # 1. Feature engineering\n",
    "        site_df = engineer_features(df, site_id)\n",
    "        if site_df.empty:\n",
    "            continue\n",
    "\n",
    "        # 2. Train & forecast\n",
    "        model, results = train_rf_forecast(site_df)\n",
    "\n",
    "        # 3. Metrics\n",
    "        metrics = compute_metrics(results[\"actual_consumption\"], results[\"forecasted_consumption\"])\n",
    "\n",
    "        # 4. Simulate inventory\n",
    "        sim_results = simulate_inventory(\n",
    "            results,\n",
    "            initial_inventory=config[\"initial_inventory\"],\n",
    "            silo_capacity=config[\"silo_capacity\"],\n",
    "            reorder_threshold=config[\"reorder_threshold\"],\n",
    "            target_inventory=config[\"target_inventory\"],\n",
    "            lead_time_days=lead_time_days\n",
    "        )\n",
    "\n",
    "        # 5. Collect metadata\n",
    "        all_metadata[site_id] = {\n",
    "            \"timestamp\": str(datetime.datetime.now()),\n",
    "            \"model_params\": model.get_params(),\n",
    "            \"metrics\": metrics,\n",
    "            \"inventory_settings\": config\n",
    "        }\n",
    "\n",
    "    # Save all site metadata\n",
    "    with open(metadata_file, \"w\") as f:\n",
    "        json.dump(all_metadata, f, indent=4)\n",
    "\n",
    "    print(f\"✅ Metadata saved for {len(all_metadata)} sites to {metadata_file}\")\n",
    "    return all_metadata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b61b61a-b2c2-4171-a5d9-263d31528707",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['site_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05935368-7420-4a1b-be86-dcb53980c11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Calculate MAPE for each site in the pipeline\n",
    "performance_summary = []\n",
    "\n",
    "for site_id in df['site_id'].unique():\n",
    "    print(f\"Evaluating model for {site_id}...\")\n",
    "    \n",
    "    # Prepare site data\n",
    "    site_df = engineer_features(df, site_id)\n",
    "    \n",
    "    if len(site_df) < 50:\n",
    "        print(f\"Skipping {site_id}, not enough data\")\n",
    "        continue\n",
    "        \n",
    "    # Features and target\n",
    "    features = [\n",
    "        'planned_pour_tonnes', 'rain_mm', 'avg_temp_c',\n",
    "        'lag_1', 'lag_3', 'lag_7',\n",
    "        'rolling_mean_3', 'rolling_std_7',\n",
    "        'rain_x_pour', 'temp_x_pour',\n",
    "        'inventory_gap', 'inventory_ratio',\n",
    "        'behavior_encoded', 'cement_type_encoded'\n",
    "    ]\n",
    "    X = site_df[features]\n",
    "    y = site_df['consumed_tonnes']\n",
    "\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Train model\n",
    "    model = LGBMRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics - handling zero values properly\n",
    "    mask = y_test != 0  # avoid division by zero\n",
    "    if mask.sum() > 0:  \n",
    "        mape = mean_absolute_percentage_error(y_test[mask], y_pred[mask]) * 100\n",
    "    else:\n",
    "        mape = 0  \n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    # Store results\n",
    "    performance_summary.append({\n",
    "        'site_id': site_id,\n",
    "        'test_samples': len(y_test),\n",
    "        'non_zero_samples': mask.sum(),\n",
    "        'mape': mape,\n",
    "        'rmse': rmse,\n",
    "        'avg_consumption': y_test.mean()\n",
    "    })\n",
    "\n",
    "# Create performance dataframe\n",
    "performance_df = pd.DataFrame(performance_summary)\n",
    "\n",
    "# Display overall performance\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OVERALL MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Average MAPE across all sites: {performance_df['mape'].mean():.2f}%\")\n",
    "print(f\"Median MAPE across all sites: {performance_df['mape'].median():.2f}%\")\n",
    "print(f\"Sites achieving MAPE ≤ 15%: {(performance_df['mape'] <= 15).sum()}/{len(performance_df)}\")\n",
    "print(f\"Sites with MAPE > 15%: {(performance_df['mape'] > 15).sum()}/{len(performance_df)}\")\n",
    "\n",
    "# Display detailed performance table\n",
    "print(\"\\nDetailed Performance by Site:\")\n",
    "print(performance_df.sort_values('mape').to_string(index=False))\n",
    "\n",
    "# Identify sites that need attention\n",
    "problem_sites = performance_df[performance_df['mape'] > 15]\n",
    "if not problem_sites.empty:\n",
    "    print(\"\\n\" + \"!\"*60)\n",
    "    print(\"SITES NEEDING ATTENTION (MAPE > 15%):\")\n",
    "    print(\"!\"*60)\n",
    "    print(problem_sites[['site_id', 'mape', 'avg_consumption', 'test_samples']].to_string(index=False))\n",
    "else:\n",
    "    print(\"\\n🎉 ALL SITES ACHIEVED TARGET MAPE OF 15% OR BETTER! 🎉\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a97459-7559-43fd-8276-fe67f7cefdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Metadata Generator ----------------\n",
    "def generate_site_metadata():\n",
    "    site_metadata = {}\n",
    "\n",
    "    site_configs = [\n",
    "        (1200, 674, 240, 960), (2500, 1421, 500, 2000), (1000, 592, 200, 800),\n",
    "        (1500, 899, 300, 1200), (1200, 640, 240, 960), (1800, 1070, 360, 1440),\n",
    "        (2000, 1198, 400, 1600), (1000, 612, 200, 800), (1500, 891, 300, 1200),\n",
    "        (2200, 1387, 440, 1760), (1200, 701, 240, 960), (1000, 603, 200, 800),\n",
    "        (1800, 1084, 360, 1440), (1500, 902, 300, 1200), (2000, 1235, 400, 1600),\n",
    "        (1200, 689, 240, 960), (2500, 1453, 500, 2000), (1500, 874, 300, 1200),\n",
    "        (1800, 1102, 360, 1440), (1000, 583, 200, 800), (2200, 1364, 440, 1760),\n",
    "        (1200, 651, 240, 960), (1500, 900, 300, 1200), (1800, 1111, 360, 1440),\n",
    "        (2000, 1180, 400, 1600), (1000, 594, 200, 800), (1200, 662, 240, 960),\n",
    "        (1500, 917, 300, 1200), (1800, 1095, 360, 1440), (2000, 1210, 400, 1600)\n",
    "    ]\n",
    "\n",
    "    for i, (capacity, inventory, threshold, target) in enumerate(site_configs, start=1):\n",
    "        site_id = f\"SITE_{i:03d}\"\n",
    "        site_metadata[site_id] = {\n",
    "            \"silo_capacity\": capacity,\n",
    "            \"initial_inventory\": inventory,\n",
    "            \"reorder_threshold\": threshold,\n",
    "            \"target_inventory\": target\n",
    "        }\n",
    "\n",
    "    return site_metadata\n",
    "\n",
    "\n",
    "# ---------------- Main ----------------\n",
    "if __name__ == \"__main__\":\n",
    "    metadata = generate_site_metadata()\n",
    "    for site, data in metadata.items():\n",
    "        print(f\"{site}: {data}\")\n",
    "\n",
    " # Convert dict → DataFrame\n",
    "    metadata_df = pd.DataFrame.from_dict(metadata, orient=\"index\").reset_index()\n",
    "    metadata_df.rename(columns={\"index\": \"site_id\"}, inplace=True)\n",
    "\n",
    "   \n",
    "    # Save to parquet\n",
    "    metadata_df.to_parquet(\"site_metadata.parquet\", index=False)\n",
    "\n",
    "    print(\" Metadata saved to site_metadata.parquet\")\n",
    "\n",
    "       \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ba22e51-220e-4995-a0fa-80708991a8fc",
   "metadata": {},
   "source": [
    "============================================================\n",
    "OVERALL MODEL PERFORMANCE SUMMARY\n",
    "==========================================================================================\n",
    "Average MAPE across all sites: 3.28%\n",
    "Median MAPE across all sites: 3.43%\n",
    "Sites achieving MAPE ≤ 15%: 30/30\n",
    "Sites with MAPE > 15%: 0/30\n",
    "\n",
    "\n",
    "🎉 ALL SITES ACHIEVED TARGET MAPE OF 15% OR BETTER! 🎉\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cabf09-9b66-40d2-bd65-7727fb8b33eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df = pd.DataFrame(performance_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad3bfba-fa7a-4dab-83c4-b72fb8aaff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94df992-fa6f-44f1-b45d-9fd79a15ef2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818b0aeb-65a6-4958-94c6-1b468eba68d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
